{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ppAhU9-pYUcv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option(\"display.max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "R1DQEdYeYZ9G",
    "outputId": "0eea8608-d11b-4477-8c02-33e6e407fa8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "O-8aC-whYfHa",
    "outputId": "841acb95-6aa6-4a1e-c697-a33140127800"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EECVE-6HYxGw"
   },
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame({'document':documents})\n",
    "\n",
    "# removing everything except alphabets`\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "\n",
    "# removing short words\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "\n",
    "# make all text lowercase\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "VnjLlUuDY2r1",
    "outputId": "82a551cc-212c-48e6-8937-f3c522dc872b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/arun/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# tokenization\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split())\n",
    "\n",
    "# remove stop-words\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "# de-tokenization\n",
    "detokenized_doc = []\n",
    "for i in range(len(news_df)):\n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    detokenized_doc.append(t)\n",
    "\n",
    "news_df['clean_doc'] = detokenized_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EeIxvPlIY525",
    "outputId": "f98ba4d4-5de9-4c87-ffb7-a35303a1d567"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', \n",
    "max_features= 1000, # keep top 1000 terms \n",
    "max_df = 0.5, \n",
    "smooth_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(news_df['clean_doc'])\n",
    "\n",
    "X.shape # check shape of the document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "elbc1jduZqtx",
    "outputId": "7a4e1201-bd41-4115-e338-d223ad447238"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# SVD represent documents and terms in vectors \n",
    "svd_model = TruncatedSVD(n_components=20, algorithm='randomized', n_iter=100, random_state=122)\n",
    "\n",
    "svd_model.fit(X)\n",
    "\n",
    "len(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pb01SngdZt6f",
    "outputId": "d024d55b-23cc-4fc7-dbb2-5b7bf1c006f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "like\n",
      " \n",
      "know\n",
      " \n",
      "people\n",
      " \n",
      "think\n",
      " \n",
      "good\n",
      " \n",
      "time\n",
      " \n",
      "thanks\n",
      " \n",
      "Topic 1: \n",
      "thanks\n",
      " \n",
      "windows\n",
      " \n",
      "card\n",
      " \n",
      "drive\n",
      " \n",
      "mail\n",
      " \n",
      "file\n",
      " \n",
      "advance\n",
      " \n",
      "Topic 2: \n",
      "game\n",
      " \n",
      "team\n",
      " \n",
      "year\n",
      " \n",
      "games\n",
      " \n",
      "season\n",
      " \n",
      "players\n",
      " \n",
      "good\n",
      " \n",
      "Topic 3: \n",
      "drive\n",
      " \n",
      "scsi\n",
      " \n",
      "disk\n",
      " \n",
      "hard\n",
      " \n",
      "card\n",
      " \n",
      "drives\n",
      " \n",
      "problem\n",
      " \n",
      "Topic 4: \n",
      "windows\n",
      " \n",
      "file\n",
      " \n",
      "window\n",
      " \n",
      "files\n",
      " \n",
      "program\n",
      " \n",
      "using\n",
      " \n",
      "problem\n",
      " \n",
      "Topic 5: \n",
      "government\n",
      " \n",
      "chip\n",
      " \n",
      "mail\n",
      " \n",
      "space\n",
      " \n",
      "information\n",
      " \n",
      "encryption\n",
      " \n",
      "data\n",
      " \n",
      "Topic 6: \n",
      "like\n",
      " \n",
      "bike\n",
      " \n",
      "know\n",
      " \n",
      "chip\n",
      " \n",
      "sounds\n",
      " \n",
      "looks\n",
      " \n",
      "look\n",
      " \n",
      "Topic 7: \n",
      "card\n",
      " \n",
      "sale\n",
      " \n",
      "video\n",
      " \n",
      "offer\n",
      " \n",
      "monitor\n",
      " \n",
      "price\n",
      " \n",
      "jesus\n",
      " \n",
      "Topic 8: \n",
      "know\n",
      " \n",
      "card\n",
      " \n",
      "chip\n",
      " \n",
      "video\n",
      " \n",
      "government\n",
      " \n",
      "people\n",
      " \n",
      "clipper\n",
      " \n",
      "Topic 9: \n",
      "good\n",
      " \n",
      "know\n",
      " \n",
      "time\n",
      " \n",
      "bike\n",
      " \n",
      "jesus\n",
      " \n",
      "problem\n",
      " \n",
      "work\n",
      " \n",
      "Topic 10: \n",
      "think\n",
      " \n",
      "chip\n",
      " \n",
      "good\n",
      " \n",
      "thanks\n",
      " \n",
      "clipper\n",
      " \n",
      "need\n",
      " \n",
      "encryption\n",
      " \n",
      "Topic 11: \n",
      "thanks\n",
      " \n",
      "right\n",
      " \n",
      "problem\n",
      " \n",
      "good\n",
      " \n",
      "bike\n",
      " \n",
      "time\n",
      " \n",
      "window\n",
      " \n",
      "Topic 12: \n",
      "good\n",
      " \n",
      "people\n",
      " \n",
      "windows\n",
      " \n",
      "know\n",
      " \n",
      "file\n",
      " \n",
      "sale\n",
      " \n",
      "files\n",
      " \n",
      "Topic 13: \n",
      "space\n",
      " \n",
      "think\n",
      " \n",
      "know\n",
      " \n",
      "nasa\n",
      " \n",
      "problem\n",
      " \n",
      "year\n",
      " \n",
      "israel\n",
      " \n",
      "Topic 14: \n",
      "space\n",
      " \n",
      "good\n",
      " \n",
      "card\n",
      " \n",
      "people\n",
      " \n",
      "time\n",
      " \n",
      "nasa\n",
      " \n",
      "thanks\n",
      " \n",
      "Topic 15: \n",
      "people\n",
      " \n",
      "problem\n",
      " \n",
      "window\n",
      " \n",
      "time\n",
      " \n",
      "game\n",
      " \n",
      "want\n",
      " \n",
      "bike\n",
      " \n",
      "Topic 16: \n",
      "time\n",
      " \n",
      "bike\n",
      " \n",
      "right\n",
      " \n",
      "windows\n",
      " \n",
      "file\n",
      " \n",
      "need\n",
      " \n",
      "really\n",
      " \n",
      "Topic 17: \n",
      "time\n",
      " \n",
      "problem\n",
      " \n",
      "file\n",
      " \n",
      "think\n",
      " \n",
      "israel\n",
      " \n",
      "long\n",
      " \n",
      "mail\n",
      " \n",
      "Topic 18: \n",
      "file\n",
      " \n",
      "need\n",
      " \n",
      "card\n",
      " \n",
      "files\n",
      " \n",
      "problem\n",
      " \n",
      "right\n",
      " \n",
      "good\n",
      " \n",
      "Topic 19: \n",
      "problem\n",
      " \n",
      "file\n",
      " \n",
      "thanks\n",
      " \n",
      "used\n",
      " \n",
      "space\n",
      " \n",
      "chip\n",
      " \n",
      "sale\n",
      " \n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(svd_model.components_):\n",
    "    terms_comp = zip(terms, comp)\n",
    "    sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:7]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_terms:\n",
    "        print(t[0])\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mD9ilV0yZwrp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Topic_modelling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
